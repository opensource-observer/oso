# NOTE: This name appears in GitHub's Checks API and in workflow's status badge.
name: ci-default
env:
  # CI variables
  DOCKER_PLATFORM: "amd64"
  #TURBO_TEAM: ${{ secrets.TURBO_TEAM }}
  #TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}
  # Frontend variables
  NODE_ENV: ${{ vars.NODE_ENV }}
  PLASMIC_PROJECT_ID: ${{ vars.PLASMIC_PROJECT_ID }}
  PLASMIC_PROJECT_API_TOKEN: ${{ vars.PLASMIC_PROJECT_API_TOKEN }}
  NEXT_PUBLIC_DOMAIN: ${{ vars.NEXT_PUBLIC_DOMAIN }}
  NEXT_PUBLIC_DB_GRAPHQL_URL: ${{ vars.NEXT_PUBLIC_DB_GRAPHQL_URL }}
  HASURA_URL: ${{ vars.HASURA_URL }}
  OSO_API_KEY: "test"
  NEXT_PUBLIC_ALGOLIA_APPLICATION_ID: "test"
  NEXT_PUBLIC_ALGOLIA_API_KEY: "test"
  NEXT_PUBLIC_ALGOLIA_INDEX: "test"
  # Docs variables
  DOCS_URL: ${{ vars.DOCS_URL }}
  DOCS_ALGOLIA_APP_ID: "test"
  DOCS_ALGOLIA_API_KEY: "test"
  DOCS_ALGOLIA_INDEX: "test"
  DOCS_GOOGLE_ANALYTICS_KEY: "test"
  # Supabase
  NEXT_PUBLIC_SUPABASE_URL: "https://test.supabase.co"
  NEXT_PUBLIC_SUPABASE_ANON_KEY: "test"
  SUPABASE_SERVICE_KEY: "test"
  SUPABASE_JWT_SECRET: "test"
  # Clickhouse variables
  CLICKHOUSE_URL: "http://127.0.0.1:8123" # dummy value
  CLICKHOUSE_USERNAME: "username"
  CLICKHOUSE_PASSWORD: "password"
  # SQLMesh variables
  SQLMESH_DUCKDB_LOCAL_PATH: "/tmp/oso.duckdb"

# Trigger the workflow when:
on:
  # A push occurs to one of the matched branches.
  push:
    branches:
      - main
  # Or when a pull request event occurs for a pull request against one of the
  # matched branches.
  #pull_request:
  pull_request_target:
    branches:
      - main
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
  merge_group:

# Cancel in progress jobs on new pushes.
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  # Authorization step will determine which environment we run in
  authorize:
    # External pull requests should run on `public`, which requires approval
    # Internal pull requests continue to run on `testing`
    environment: ${{ github.event_name == 'pull_request_target' && github.event.pull_request.head.repo.full_name != github.repository && 'public' || 'testing' }}
    runs-on: ubuntu-latest
    steps:
      - run: true

  build-lint-test:
    # NOTE: This name appears in GitHub's Checks API.
    name: test
    environment: ${{ github.event_name == 'pull_request_target' && github.event.pull_request.head.repo.full_name != github.repository && 'public' || 'testing' }}
    needs: authorize
    runs-on: ubuntu-latest
    strategy:
      matrix:
        # PRIORITY ORDER: python → sqlmesh → sqlmesh-docker → node
        component: ["python", "sqlmesh", "sqlmesh-docker", "node"] # "dbt"
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          # Check out pull request's HEAD commit instead of the merge commit to
          # prevent gitlint from failing due to too long commit message titles,
          # e.g. "Merge 3e621938d65caaa67f8e35d145335d889d470fc8 into 19a39b2f66cd7a165082d1486b2f1eb36ec2354a".
          ref: ${{ github.event.pull_request.head.sha || github.ref }}
          # Fetch all history so gitlint can check the relevant commits.
          fetch-depth: "0"

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
          run_install: |
            - recursive: true
              args: [--frozen-lockfile, --strict-peer-dependencies]

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20.x"
          cache: "pnpm"

      - name: Setup Python and UV
        uses: astral-sh/setup-uv@v5
        with:
          python-version: 3.12

      - name: Install dependencies
        run: uv sync --all-packages --all-extras

      # ─────────────────────────────────────────────────────────────────────
      # Python steps
      - name: Type Check (Python)
        run: pnpm pyright
        if: ${{ always() && matrix.component == 'python' }}

      - name: Lint (Python)
        run: uv run ruff check
        if: ${{ always() && matrix.component == 'python' }}

      - name: Test (Python)
        run: uv run pytest
        if: ${{ always() && matrix.component == 'python' }}

      - name: Lint SQLMesh
        working-directory: warehouse
        run: | 
          uv run oso local sqlmesh lint
        if: ${{ always() && matrix.component == 'sqlmesh-docker' || matrix.component == 'sqlmesh' }}

      # ─────────────────────────────────────────────────────────────────────
      # SQLMesh steps
      - name: Test SQLMesh (DuckDB)
        working-directory: warehouse
        run: |
          uv run oso local sqlmesh-test --duckdb plan dev --start '1 week' --end now --auto-apply
        if: ${{ always() && matrix.component == 'sqlmesh' }}

      - name: Test SQLMesh (Docker)
        working-directory: warehouse
        run: |
          uv run oso local sqlmesh-test plan dev --start '1 week' --end now --auto-apply
        if: ${{ always() && matrix.component == 'sqlmesh-docker' }}

      # ─────────────────────────────────────────────────────────────────────
      # Node steps
      - name: Run supabase local
        id: supabase
        run: |
          bash .github/scripts/run-supabase-local.sh apps/frontend
        if: ${{ matrix.component == 'node' }}

      - name: Build (Node)
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 5
          max_attempts: 3
          command: pnpm build
        if: ${{ matrix.component == 'node' }}

      - name: Lint (Node)
        run: pnpm lint
        if: ${{ always() && matrix.component == 'node' }}
        #if: ${{ always() && steps.supabase.conclusion == 'success' && matrix.component == 'node' }}

      - name: Test (Node)
        run: pnpm test
        if: ${{ always() && matrix.component == 'node' }}
        #if: ${{ always() && steps.supabase.conclusion == 'success' &&  matrix.component == 'node' }}
