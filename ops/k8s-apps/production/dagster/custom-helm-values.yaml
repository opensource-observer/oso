apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: production-dagster
spec:
  values:
    # We should eventually set this to 0, but we are setting it to 1 to gather
    # timing data
    osoDagster:
      eagerlyLoadSqlTables: 0
      env: "production"
      gcp:
        enabled: true
        bigquery:
          enabled: true
      testAssets:
        # This should normally be off, but if we need to test some failure
        # scenarios on production enable this
        enabled: true
    pg:
      host: production-cloudsql-proxy-gcloud-sqlproxy.production-cloudsql-proxy.svc.cluster.local
      port: "5432"
    global:
      serviceAccountName: production-dagster
    configMap:
      secretPrefix: "gcp:secretmanager:production-dagster"
    alerts:
      baseUrl: "https://dagster.opensource.observer"
    cache:
      uri: "redis://redis.production-redis.svc.cluster.local:6379?ttl=3600"
    dagster:
      global:
        serviceAccountName: production-dagster
      ingress:
        enabled: true
        ingressClassName: ingress-internal-cloudflare
        dagsterWebserver:
          host: admin-dagster.opensource.observer
        readOnlyDagsterWebserver:
          host: dagster.opensource.observer
      dagsterDaemon:
        runRetries:
          enabled: true
          maxRetries: 3
        runMonitoring:
          startTimeoutSeconds: 600
        env:
          - name: DAGSTER_DBT_GENERATE_AND_AUTH_GCP
            value: "1"
        resources:
          limits:
            memory: 1280Mi
          requests:
            cpu: 200m
            memory: 640Mi
      dagsterWebserver:
        env:
          - name: DAGSTER_DBT_GENERATE_AND_AUTH_GCP
            value: "1"
        resources:
          limits:
            memory: 1024Mi
          requests:
            cpu: 100m
            memory: 512Mi
      runLauncher:
        config:
          k8sRunLauncher:
            runK8sConfig:
              podSpecConfig:
                tolerations:
                  - key: pool_type
                    effect: NoSchedule
                    operator: Equal
                    value: standard
                nodeSelector:
                  pool_type: standard
              containerConfig:
                resources:
                  limits:
                    memory: 2048Mi
                  requests:
                    cpu: 100m
                    memory: 1024Mi
      dagster-user-deployments:
        deployments:
          - name: "default"
            image:
              repository: ghcr.io/opensource-observer/oso # {"$imagepolicy": "flux-system:oso:name"}
              tag: deploy-20250823025101-34ffd1c # {"$imagepolicy": "flux-system:oso:tag"}
              pullPolicy: IfNotPresent
            envConfigMaps:
              - name: dagster-oso-extra-env
            port: 3030
            dagsterApiGrpcArgs:
              - "-m"
              - "oso_dagster.definitions.default"
              - "--log-format"
              - "json"
            includeConfigInLaunchedRuns:
              enabled: false
    sqlmesh:
      gateway: "trino"
      trino:
        host: production-trino-trino.production-trino.svc.cluster.local
        user: sqlmesh
        catalog: "iceberg"
        concurrentTasks: "64"
        k8s:
          coordinatorDeploymentName: production-trino-trino-coordinator
          workerDeploymentName: production-trino-trino-worker
          serviceName: production-trino-trino
          namespace: production-trino
      mcs:
        enabled: true
        skipRolling: true
        url: "http://production-mcs.production-mcs.svc.cluster.local:8000"
        k8s:
          deploymentName: production-mcs
          serviceName: production-mcs
          namespace: production-mcs
